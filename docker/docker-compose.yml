version: "3"
services:
  # Create a service called spark-master
  spark-master:
    image: "spark_master"
    ports:
      - "8080:8080"
    networks:
      - spark-net
    volumes:
      - spocker:/spark/data
    # deploy:
    #   placement:
        # set node labels using docker node update --label-add key=value <NODE ID> from swarm manager
        # constraints:
        #   - node.labels.role==master
  # Create a second service called spark-worker
  spark-worker:
    image: "spark_worker"
    ports:
      - "8081:8081"
    environment:
      - CORES=3
      - MEMORY=15G
    deploy:
    #   placement:
        # set node labels using docker node update --label-add key=value <NODE ID> from swarm manager
        # constraints:
        #   - node.labels.role==worker
      # Deploy 3 containers for this service
      replicas: 3
    networks:
      - spark-net
    volumes:
      - spocker:/spark/data
  # Create a second service called spark-worker
  spark-submit:
    image: "spark_submit"
    entrypoint: "tail -f /dev/null"
    ports:
      - "4040:4040"
      - "8888:8888"
      - "8889:8889"
    environment:
      # - SPARK_SUBMIT_WEBUI_PORT=4040
      - SPARK_WEBUI=4040
    networks:
      - spark-net
    volumes:
      - spocker:/spark/data
      - control_node:/spark/code
# Create the spark-net network
networks:
  spark-net:
    driver: overlay
volumes:
  spocker:
    external: true
  control_node:
    external: true
